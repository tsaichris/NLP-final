{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc100dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import langchain\n",
    "\n",
    "# Langsmith\n",
    "langchain.debug = False\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"false\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"\"\n",
    "# if \"LANGSMITH_API_KEY\" not in os.environ:\n",
    "#     os.environ[\"LANGSMITH_API_KEY\"] = \"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\"\n",
    "# if \"LANGSMITH_PROJECT\" not in os.environ:\n",
    "#     os.environ[\"LANGSMITH_PROJECT\"] = \"nlp_final\"\n",
    "\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = \"\"\n",
    "\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2727bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmmlu_preparer\n",
    "from mmmlu_preparer.read_mmmlu_dataset import (\n",
    "    TARGET_SUBTASKS,\n",
    "    MMMLULanguage,\n",
    "    create_mmmlu_dataset,\n",
    "    sample_first_n_data_from_subtask\n",
    ")\n",
    "\n",
    "lang_list = [\"EN\", \"JA_JP\"]\n",
    "curr_language = lang_list[0]\n",
    "dataset_language_enum = MMMLULanguage[curr_language]\n",
    "\n",
    "mmmlu_ds = create_mmmlu_dataset(dataset_language_enum)\n",
    "chosen_subtasks = TARGET_SUBTASKS\n",
    "mmmlu_subset = sample_first_n_data_from_subtask(mmmlu_ds, chosen_subtasks)\n",
    "mmmlu_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc628684",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmmlu_preparer.answer_extract import extract_answer_from_response\n",
    "print(extract_answer_from_response(\"TEST A TEST\"))\n",
    "print(extract_answer_from_response(\"Answer: B\"))\n",
    "print(extract_answer_from_response(\"<Answer> D\"))\n",
    "print(extract_answer_from_response(\"'Answer': C\"))\n",
    "print(extract_answer_from_response('\"Answer\": A'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd3709d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Draft\n",
    "experiment_save_dict = {\n",
    "    \"Model\": \"\",\n",
    "    \"Question id\": \"\",\n",
    "    \"Shuffle method\": \"\",\n",
    "    \"Original to shuffled\": \"\",\n",
    "    \"Input format\": \"\",\n",
    "    \"Output format\": \"\",\n",
    "    \"Query\": \"\",\n",
    "    \"Language\": \"\",\n",
    "    \"Subtask\": \"\",\n",
    "    \"Original correct answer\": \"\",\n",
    "    \"Shuffled correct answer\": \"\",\n",
    "    \"Response answer\": \"\",\n",
    "    \"Model output\": \"\",  # Output text only\n",
    "    \"Full response\": \"\", # All the output\n",
    "}\n",
    "\n",
    "experiment_list = [experiment_save_dict]\n",
    "experiment_df = pd.DataFrame(experiment_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb73003",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a76ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "save_dir = \"./mmmlu_output\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5a272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
    "\n",
    "try:\n",
    "    # load environment variables from .env file (requires `python-dotenv`)\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "\n",
    "# Gemini 2.0 Flash Free rate: RPM 15\n",
    "# Tier 1 RPM 2000\n",
    "rate_limiter = InMemoryRateLimiter(\n",
    "    requests_per_second=20,\n",
    "    check_every_n_seconds=0.1,\n",
    "    max_bucket_size=20,\n",
    ")\n",
    "\n",
    "\n",
    "model_name = \"gemini-2.0-flash\"\n",
    "model = init_chat_model(model_name,\n",
    "                        model_provider=\"google_genai\",\n",
    "                        rate_limiter=rate_limiter,\n",
    "                        temperature=0.0,\n",
    "                        max_tokens=4096\n",
    "                        )\n",
    "\n",
    "# text: The text to translate\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"user\", \"{text}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4286549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmmlu_preparer.query_formats import (\n",
    "    get_current_queries,\n",
    "    InputFormat,\n",
    "    OutputFormat,\n",
    "    ShuffleMethod\n",
    ")\n",
    "\n",
    "# BASE, JSON, XML\n",
    "curr_input_format = InputFormat.BASE\n",
    "\n",
    "# BASE, JSON_FULL, XML_FULL\n",
    "curr_output_format = OutputFormat.BASE\n",
    "\n",
    "# DEFAULT, REVERSE, LONGEST_FIRST, SHORTEST_FIRST, MOST_KANA_RATIO, FEWEST_KANA_RATIO\n",
    "curr_shuffle_method = ShuffleMethod.DEFAULT\n",
    "\n",
    "input_format_save_name = curr_input_format.value.lower().replace(\"_\", \"-\")\n",
    "output_format_save_name = curr_output_format.name.lower().replace(\"_\", \"-\")\n",
    "shuffle_method_save_name = curr_shuffle_method.name.lower().replace(\"_\", \"-\")\n",
    "\n",
    "language_name = curr_language.lower().replace(\"_\", \"-\")\n",
    "\n",
    "save_name = f\"{model_name}_{language_name}_{input_format_save_name}_input_{output_format_save_name}_output_{shuffle_method_save_name}_shuffle\"\n",
    "save_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87522be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_queries = get_current_queries(mmmlu_subset,\n",
    "                                   dataset_language_enum,\n",
    "                                   chosen_subtasks,\n",
    "                                   curr_input_format,\n",
    "                                   curr_output_format,\n",
    "                                   curr_shuffle_method,\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6a03ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmmlu_subset.filter(lambda x: x['Subject'] == \"abstract_algebra\")[0]['Question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d931d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(curr_queries[0]['Query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc528d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm.auto import trange\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "async def run_experiemnts(queries: list[dict], save_path: str, try_first_n: Optional[int] = None) -> list[dict]:\n",
    "    text_queries = [{\"text\": query['Query']} for query in queries]\n",
    "    input_prompts = prompt_template.batch(text_queries)\n",
    "\n",
    "    results = []\n",
    "    mini_batch_size = 20\n",
    "\n",
    "    target_save_path = Path(save_path)\n",
    "    if target_save_path.suffix != \".jsonl\":\n",
    "        print(\"Output should be jsonl file\")\n",
    "        target_save_path = target_save_path.with_suffix(\".jsonl\")\n",
    "    target_save_path.touch()\n",
    "\n",
    "    with target_save_path.open('r', encoding='utf-8') as file:\n",
    "        # Count the nubmer of lines\n",
    "        start_idx = sum(1 for line in file if line.strip())\n",
    "    print(f\"Start from {start_idx = }\")\n",
    "\n",
    "    total_process_num = len(text_queries)\n",
    "    if try_first_n is not None:\n",
    "        total_process_num = start_idx + try_first_n\n",
    "\n",
    "    for batch_i in trange(start_idx, total_process_num, mini_batch_size):\n",
    "        try:\n",
    "            batched_prompts = input_prompts[batch_i:batch_i + mini_batch_size]\n",
    "            responses = await model.abatch(batched_prompts)\n",
    "            results.extend(responses)\n",
    "            with target_save_path.open('a', encoding='utf-8') as file:\n",
    "                for response in responses:\n",
    "                    json.dump(response.to_json(), file, ensure_ascii=False)\n",
    "                    file.write(\"\\n\")\n",
    "                file.flush()\n",
    "            print(f\"Finish {batch_i + mini_batch_size} data\")\n",
    "        except Exception as e:\n",
    "            # Rate limit break\n",
    "            print(f\"Current idx:{batch_i}\\nencounters exception: {e}\\nIt might be daily rate limit or error.\")\n",
    "            break\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab3e311",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = f\"{save_dir}/{save_name}.jsonl\"\n",
    "results = await run_experiemnts(curr_queries, save_path, try_first_n=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f2b356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "save_path = f\"{save_dir}/{save_name}.jsonl\"\n",
    "target_save_path = Path(save_path)\n",
    "with target_save_path.open('r', encoding='utf-8') as file:\n",
    "    result_dicts = [json.loads(line) for line in file if line.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480ac99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_dicts[1]['kwargs']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1144e278",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_text = [result['kwargs']['content'] for result in result_dicts]\n",
    "output_answer = []\n",
    "none_answer_indice = []\n",
    "none_answer_output = []\n",
    "for idx, output in enumerate(output_text):\n",
    "    extracted_answer = extract_answer_from_response(output)\n",
    "    output_answer.append(extracted_answer)\n",
    "    if extracted_answer is None:\n",
    "        none_answer_indice.append(idx)\n",
    "        none_answer_output.append(output)\n",
    "        #print(idx)\n",
    "        print(f\"{idx}:\\n{output = }\\n\")\n",
    "\n",
    "print(f\"{len(none_answer_indice) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0844c5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "output_tokens_list = [result['kwargs']['usage_metadata']['total_tokens'] for result in result_dicts]\n",
    "print(np.argsort(-np.array(output_tokens_list)).tolist())\n",
    "print(np.sort(-np.array(output_tokens_list)).tolist())\n",
    "print(f\"median: {np.median(output_tokens_list)}\")\n",
    "print(f\"mean: {np.mean(output_tokens_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9c897a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_dicts[7]['kwargs']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a09a431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.output_parsers.json import JsonOutputParser\n",
    "# import re\n",
    "# from tqdm.auto import tqdm\n",
    "# parser = JsonOutputParser()\n",
    "\n",
    "# for result in tqdm(result_dicts):\n",
    "#     #try:\n",
    "#     string = result['kwargs']['content']\n",
    "\n",
    "#     def escape_single_backslash(match):\n",
    "#         c = match.group(0)\n",
    "#         return c.replace(\"\\\\\", \"\\\\\\\\\")\n",
    "\n",
    "#     # ChatGPT\n",
    "#     string = re.sub(r'(?<!\\\\)\\\\(?![\\\\ntbrf\"u])', escape_single_backslash, string)\n",
    "\n",
    "#     x = (parser.parse(string))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
