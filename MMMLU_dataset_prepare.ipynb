{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee33aefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "from datasets import Value\n",
    "\n",
    "first_four_letters = string.ascii_uppercase[:4]\n",
    "def to_mmmlu_format(mmlu_dataset):\n",
    "    for col_name in mmlu_dataset.features:\n",
    "        mmlu_dataset = mmlu_dataset.rename_column(col_name, col_name.capitalize())\n",
    "    choice_arr = np.array(mmlu_dataset['Choices'])\n",
    "    for idx, letter in enumerate(first_four_letters):\n",
    "        mmlu_dataset = mmlu_dataset.add_column(letter, choice_arr[:, idx])\n",
    "    mmlu_dataset = mmlu_dataset.remove_columns('Choices')\n",
    "\n",
    "    # From number answer to letter answer\n",
    "    mmlu_dataset = mmlu_dataset.cast_column('Answer', Value('string'))\n",
    "    mmlu_dataset = mmlu_dataset.map(lambda x: {\"Answer\": first_four_letters[int(x['Answer'])]})\n",
    "    return mmlu_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49c1cc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "# [English, ZH_CN]\n",
    "lang_list = [\"English\", \"ZH_CN\"]\n",
    "curr_lang = lang_list[-1]\n",
    "if curr_lang == 'English':\n",
    "    mmmlu_ds = load_dataset('cais/mmlu', 'all', split='test')\n",
    "    mmmlu_ds = to_mmmlu_format(mmmlu_ds)\n",
    "else:\n",
    "    mmmlu_ds = load_dataset(\"openai/MMMLU\", curr_lang, split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abd42850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/hendrycks/test/blob/master/categories.py\n",
    "subcategories = {\n",
    "    \"abstract_algebra\": [\"math\"],\n",
    "    \"anatomy\": [\"health\"],\n",
    "    \"astronomy\": [\"physics\"],\n",
    "    \"business_ethics\": [\"business\"],\n",
    "    \"clinical_knowledge\": [\"health\"],\n",
    "    \"college_biology\": [\"biology\"],\n",
    "    \"college_chemistry\": [\"chemistry\"],\n",
    "    \"college_computer_science\": [\"computer science\"],\n",
    "    \"college_mathematics\": [\"math\"],\n",
    "    \"college_medicine\": [\"health\"],\n",
    "    \"college_physics\": [\"physics\"],\n",
    "    \"computer_security\": [\"computer science\"],\n",
    "    \"conceptual_physics\": [\"physics\"],\n",
    "    \"econometrics\": [\"economics\"],\n",
    "    \"electrical_engineering\": [\"engineering\"],\n",
    "    \"elementary_mathematics\": [\"math\"],\n",
    "    \"formal_logic\": [\"philosophy\"],\n",
    "    \"global_facts\": [\"other\"],\n",
    "    \"high_school_biology\": [\"biology\"],\n",
    "    \"high_school_chemistry\": [\"chemistry\"],\n",
    "    \"high_school_computer_science\": [\"computer science\"],\n",
    "    \"high_school_european_history\": [\"history\"],\n",
    "    \"high_school_geography\": [\"geography\"],\n",
    "    \"high_school_government_and_politics\": [\"politics\"],\n",
    "    \"high_school_macroeconomics\": [\"economics\"],\n",
    "    \"high_school_mathematics\": [\"math\"],\n",
    "    \"high_school_microeconomics\": [\"economics\"],\n",
    "    \"high_school_physics\": [\"physics\"],\n",
    "    \"high_school_psychology\": [\"psychology\"],\n",
    "    \"high_school_statistics\": [\"math\"],\n",
    "    \"high_school_us_history\": [\"history\"],\n",
    "    \"high_school_world_history\": [\"history\"],\n",
    "    \"human_aging\": [\"health\"],\n",
    "    \"human_sexuality\": [\"culture\"],\n",
    "    \"international_law\": [\"law\"],\n",
    "    \"jurisprudence\": [\"law\"],\n",
    "    \"logical_fallacies\": [\"philosophy\"],\n",
    "    \"machine_learning\": [\"computer science\"],\n",
    "    \"management\": [\"business\"],\n",
    "    \"marketing\": [\"business\"],\n",
    "    \"medical_genetics\": [\"health\"],\n",
    "    \"miscellaneous\": [\"other\"],\n",
    "    \"moral_disputes\": [\"philosophy\"],\n",
    "    \"moral_scenarios\": [\"philosophy\"],\n",
    "    \"nutrition\": [\"health\"],\n",
    "    \"philosophy\": [\"philosophy\"],\n",
    "    \"prehistory\": [\"history\"],\n",
    "    \"professional_accounting\": [\"other\"],\n",
    "    \"professional_law\": [\"law\"],\n",
    "    \"professional_medicine\": [\"health\"],\n",
    "    \"professional_psychology\": [\"psychology\"],\n",
    "    \"public_relations\": [\"politics\"],\n",
    "    \"security_studies\": [\"politics\"],\n",
    "    \"sociology\": [\"culture\"],\n",
    "    \"us_foreign_policy\": [\"politics\"],\n",
    "    \"virology\": [\"health\"],\n",
    "    \"world_religions\": [\"philosophy\"],\n",
    "}\n",
    "\n",
    "categories = {\n",
    "    \"STEM\": [\"physics\", \"chemistry\", \"biology\", \"computer science\", \"math\", \"engineering\"],\n",
    "    \"humanities\": [\"history\", \"philosophy\", \"law\"],\n",
    "    \"social sciences\": [\"politics\", \"culture\", \"economics\", \"geography\", \"psychology\"],\n",
    "    \"other (business, health, misc.)\": [\"other\", \"business\", \"health\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "103db822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the first subtask in the subcategory\n",
    "subtasks = {}\n",
    "chosen_subtasks = []\n",
    "for subtask, task_subcategory in subcategories.items():\n",
    "    curr_category = task_subcategory[0]\n",
    "    if curr_category not in subtasks:\n",
    "        subtasks[curr_category] = []\n",
    "        chosen_subtasks.append(subtask)\n",
    "    subtasks[curr_category].append(subtask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39f89fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abstract_algebra',\n",
       " 'anatomy',\n",
       " 'astronomy',\n",
       " 'business_ethics',\n",
       " 'college_biology',\n",
       " 'college_chemistry',\n",
       " 'college_computer_science',\n",
       " 'econometrics',\n",
       " 'electrical_engineering',\n",
       " 'formal_logic',\n",
       " 'global_facts',\n",
       " 'high_school_european_history',\n",
       " 'high_school_geography',\n",
       " 'high_school_government_and_politics',\n",
       " 'high_school_psychology',\n",
       " 'human_sexuality',\n",
       " 'international_law']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_subtasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc1fae28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import concatenate_datasets\n",
    "datasets.disable_progress_bar()\n",
    "def sample_first_n_data_from_subtask(ds, subtasks, first_n=100,):\n",
    "    sampled_ds_list = []\n",
    "    indice = range(first_n)\n",
    "    for subtask in subtasks:\n",
    "        curr_ds = ds.filter(lambda x: x['Subject'] == subtask)\n",
    "        sampled = curr_ds.select(indice)\n",
    "        sampled_ds_list.append(sampled)\n",
    "    return concatenate_datasets(sampled_ds_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f178d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Unnamed: 0', 'Question', 'A', 'B', 'C', 'D', 'Answer', 'Subject'],\n",
       "    num_rows: 1700\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_first_n_data_from_subtask(mmmlu_ds, chosen_subtasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e56cfd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# common.py\n",
    "QUERY_TEMPLATE_MULTICHOICE = \"\"\"\n",
    "Answer the following multiple choice question. The last line of your response should be of the following format: 'Answer: $LETTER' (without quotes) where LETTER is one of ABCD. Think step by step before answering.\n",
    "\n",
    "{Question}\n",
    "\n",
    "A) {A}\n",
    "B) {B}\n",
    "C) {C}\n",
    "D) {D}\n",
    "\"\"\".strip()\n",
    "\n",
    "BASE_TEMPLATE_PLAIN = \"\"\"\n",
    "Answer the following multiple choice question. {Output_format} Think step by step before answering.\n",
    "\n",
    "{Question}\n",
    "\n",
    "A) {A}\n",
    "B) {B}\n",
    "C) {C}\n",
    "D) {D}\n",
    "\"\"\".strip()\n",
    "\n",
    "BASE_TASK = \"Answer the following multiple choice question.\"\n",
    "BASE_OUPUT_FORMAT = \"The last line of your response should be of the following format: 'Answer: $LETTER' (without quotes) where LETTER is one of ABCD.\"\n",
    "BASE_INSTRUCRTION = \"Think step by step before answering.\"\n",
    "\n",
    "JSON_OUPUT_FORMAT = \"\"\"The last line of your response should be of the following format:\n",
    "'\n",
    "{\n",
    "    \"Answer\": \"$LETTER\"\n",
    "}\n",
    "'\n",
    "where LETTER is one of ABCD. Namely, a json format for the output is required.\n",
    "\"\"\"\n",
    "\n",
    "XML_OUPUT_FORMAT = \"\"\"The last line of your response should be of the following format:\n",
    "'\n",
    "<root>\n",
    "    <Answer> $LETTER </Answer>\n",
    "</root>\n",
    "'\n",
    "where LETTER is one of ABCD. Namely, a XML format for the output is required.\n",
    "\"\"\"\n",
    "\n",
    "# Draft Json. Not confirm\n",
    "JSON_TEMPLATE_DICT = {\n",
    "    \"Task\": None,\n",
    "    \"Output_format\": None,\n",
    "    \"Instruction\": None,\n",
    "    \"Question\": None,\n",
    "    \"A\": None,\n",
    "    \"B\": None,\n",
    "    \"C\": None,\n",
    "    \"D\": None\n",
    "}\n",
    "\n",
    "# Fill task and instruction from base prompt\n",
    "base_json_dict = JSON_TEMPLATE_DICT.copy()\n",
    "base_json_dict['Task'] = BASE_TASK\n",
    "base_json_dict['Instruction'] = BASE_INSTRUCRTION\n",
    "\n",
    "DEFAULT_ORDER = np.array([\"A\", \"B\", \"C\", \"D\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47378d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import copy\n",
    "\n",
    "root = ET.Element(\"root\")\n",
    "task_tag = ET.SubElement(root, 'Task')\n",
    "task_tag.text = BASE_TASK\n",
    "\n",
    "output_tag = ET.SubElement(root, \"Output_format\")\n",
    "instruction_tag = ET.SubElement(root, \"Instruction\")\n",
    "instruction_tag.text = BASE_INSTRUCRTION\n",
    "\n",
    "question_tag = ET.SubElement(root, \"Qeustion\")\n",
    "a_tag = ET.SubElement(root, \"A\")\n",
    "b_tag = ET.SubElement(root, \"B\")\n",
    "c_tag = ET.SubElement(root, \"C\")\n",
    "d_tag = ET.SubElement(root, \"D\")\n",
    "\n",
    "ET.indent(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76ef90ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<root>\n",
      "  <Task>Answer the following multiple choice question.</Task>\n",
      "  <Output_format />\n",
      "  <Instruction>Think step by step before answering.</Instruction>\n",
      "  <Qeustion />\n",
      "  <A />\n",
      "  <B />\n",
      "  <C />\n",
      "  <D />\n",
      "</root>\n"
     ]
    }
   ],
   "source": [
    "ET.dump(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f1ec39e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The last line of your response should be of the following format:\\n\\'\\n{\\n    \"Answer\": \"$LETTER\"\\n}\\n\\'\\nwhere LETTER is one of ABCD. Namely, a json format for the output is required.\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JSON_OUPUT_FORMAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7ac599e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Task\": \"Answer the following multiple choice question.\",\n",
      "    \"Output_format\": null,\n",
      "    \"Instruction\": \"Think step by step before answering.\",\n",
      "    \"Question\": null,\n",
      "    \"A\": null,\n",
      "    \"B\": null,\n",
      "    \"C\": null,\n",
      "    \"D\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# Get Json string\n",
    "query_json_string = json.dumps(base_json_dict, ensure_ascii=False, indent=4)\n",
    "print(query_json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c730cc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Task\": \"Answer the following multiple choice question.\",\n",
      "    \"Output_format\": \"The last line of your response should be of the following format: 'Answer: $LETTER' (without quotes) where LETTER is one of ABCD.\",\n",
      "    \"Instruction\": \"Think step by step before answering.\",\n",
      "    \"Question\": \"罗马声称他们的主教（教皇）是哪个领袖的继位人？\",\n",
      "    \"A\": \"马修\",\n",
      "    \"B\": \"耶稣\",\n",
      "    \"C\": \"保罗\",\n",
      "    \"D\": \"彼得\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def get_perumte_map(options, permute_method=None, output_format=None):\n",
    "    # Temp\n",
    "    match permute_method:\n",
    "        case \"reverse\":\n",
    "            permutation = np.flip(DEFAULT_ORDER)\n",
    "        case \"long-first\":\n",
    "            sort_by_long = np.flip(np.argsort(np.char.str_len(options)))\n",
    "            permutation = DEFAULT_ORDER[sort_by_long]\n",
    "        case \"short-first\":\n",
    "            sort_by_short = np.argsort(np.char.str_len(options))\n",
    "            permutation = DEFAULT_ORDER[sort_by_short]\n",
    "        case _:\n",
    "            permutation = DEFAULT_ORDER\n",
    "    return {opt: permutation[idx] for idx, opt in enumerate(DEFAULT_ORDER)}\n",
    "\n",
    "def get_output_format(output_format_type=None):\n",
    "    if output_format_type is None:\n",
    "        output_format_type = \"\"\n",
    "    match output_format_type.lower():\n",
    "        case \"json\":\n",
    "            return JSON_OUPUT_FORMAT\n",
    "        case \"xml\":\n",
    "            return XML_OUPUT_FORMAT\n",
    "        case _:\n",
    "            return BASE_OUPUT_FORMAT\n",
    "\n",
    "\n",
    "# Base Prompt\n",
    "def get_query_permute_pair(curr_question, permute_method=None, output_format_type=None):\n",
    "    query = BASE_TEMPLATE_PLAIN\n",
    "    output_format = get_output_format(output_format_type)\n",
    "\n",
    "    options = [curr_question[opt] for opt in DEFAULT_ORDER]\n",
    "    option_mapping = get_perumte_map(options, permute_method)\n",
    "\n",
    "    query_filling = {option_mapping[opt]: curr_question[opt].strip() for opt in DEFAULT_ORDER}\n",
    "    query_filling['Question'] = curr_question['Question'].strip()\n",
    "    query_filling[\"Output_format\"] = output_format\n",
    "    return query.format_map(query_filling), option_mapping\n",
    "\n",
    "# Json input, arbitrary output\n",
    "def get_json_query_permute_pair(curr_question, permute_method=None, output_format_type=None):\n",
    "    query_dict = base_json_dict.copy()\n",
    "    output_format = get_output_format(output_format_type)\n",
    "\n",
    "    options = [curr_question[opt] for opt in DEFAULT_ORDER]\n",
    "    option_mapping = get_perumte_map(options, permute_method)\n",
    "\n",
    "    query_filling = {option_mapping[opt]: curr_question[opt].strip() for opt in DEFAULT_ORDER}\n",
    "    query_filling['Question'] = curr_question['Question'].strip()\n",
    "    query_filling['Output_format'] = output_format\n",
    "    query_dict.update(query_filling)\n",
    "    json_query = json.dumps(query_dict, ensure_ascii=False, indent=4)\n",
    "    return json_query, option_mapping\n",
    "\n",
    "\n",
    "for curr_subtask in chosen_subtasks:\n",
    "    curr_ds = mmmlu_ds.filter(lambda x: x['Subject'] == subtask)\n",
    "    curr_query, curr_mapping = get_json_query_permute_pair(curr_ds[42], permute_method=\"reverse\")\n",
    "    curr_ans = curr_mapping[curr_ds[0]['Answer']] # Get the new position of answer\n",
    "    print(curr_query)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2f3ba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "# Accuracy, F1, ...\n",
    "\n",
    "# FR: total samples N, mean(response_forward != response_backward)\n",
    "\n",
    "# RStd: the num of options k, compute deviation of recall\n",
    "\n",
    "# RSD: the num of options k, compute deviation of accuracy divided by average acc.\n",
    "\n",
    "# CKLD: the num of options k, the ratio of ground truth i-label p_i, ratio of predicted i-label q_i,\n",
    "# mean(p_i * log(p_i / q_i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
